```{r,eval=F,echo=F}
library(knitr)
knit("tutorial.rmd","tutorial.md")
library(markdown)
markdownToHTML("tutorial.md","tutorial.html")
```

# Missing data

## Load the dataset

```{r}
library(mice)
```

```{r}
load("dataset/dataset.rda")
idx <- match(rownames(sva.smoking), colnames(meth))
meth <- meth[,idx]
samples <- samples[idx,]
sva.age <- sva.age[idx,]
```

Double-check that data objects are synchronized.
```{r}
stopifnot(identical(rownames(sva.smoking), colnames(meth)))
stopifnot(identical(rownames(sva.smoking), as.character(samples$gsm)))
stopifnot(identical(rownames(sva.smoking), rownames(sva.age)))
```

Make sure that character variables are factors.
```{r}
for (i in 1:ncol(samples))
    if (is.character(samples[[i]]))
        samples[[i]] <- as.factor(samples[[i]])
```

Remove the 'gsm' (individual id) and 'gse' (dataset) variables
since no individual has more than methylation profile.
```{r}
samples$gsm <- samples$gse <- NULL
```

```{r,echo=FALSE,eval=FALSE}
## code to identify useful CpG sites for the examples below
library(limma)
design <- model.matrix(~ ., cbind(samples, sva.age))
fit <- eBayes(lmFit(meth, design))
```

## Exploring missing patterns

We'll be randomly removing data.
To make these analyses repeatable, we
set a random seed.
```{r}
set.seed(20180312)
```

Remove 20 values from smoking status and age.
```{r}
samples.mis <- samples
samples.mis$smoking[sample(1:nrow(samples.mis), 20)] <- NA
samples.mis$age[sample(1:nrow(samples.mis),20)] <- NA
```

Have a look at the missingness pattern.
```{r}
md.pattern(samples.mis)
```

According to the `mice::md.pattern()` documentation:
> A matrix with ‘ncol(x)+1’ columns, in which each row corresponds
> to a missing data pattern (1=observed, 0=missing).  Rows and
> columns are sorted in increasing amounts of missing information.
> The last column and row contain row and column counts,
> respectively.

```{r}
sum(is.na(samples.mis$age) & is.na(samples.mis$smoking))
sum(is.na(samples.mis$age) & !is.na(samples.mis$smoking))
sum(!is.na(samples.mis$age) & is.na(samples.mis$smoking))
sum(!is.na(samples.mis$age) & !is.na(samples.mis$smoking))
```

## Missing completely at random

To keep things simple for now,
we'll analyse data with only one variable (smoking status)
missing values.  Well remove 20% of the values.
```{r}
pct.missing <- 0.2
```

The way we remove the values, data should be 'missing completely at random'.
```{r}
samples.mcar <- samples
missing.idx <- sample(1:nrow(samples.mcar),
                      floor(pct.missing*nrow(samples.mcar)))
samples.mcar$smoking[missing.idx] <- NA
```

Have a look at the missingness patterns.
```{r}
table(samples.mcar$smoking, useNA="a")
md.pattern(data.frame(samples.mcar))
```

Now we test if smoking status missingness is associated with
any other variables of interest.
```{r}
coef(summary(glm(is.na(smoking) ~ age + sex, data=samples.mcar, family="binomial")))
```

Assuming that age and sex are the only external variables of interest here,
we have shown that smoking status is missing completely at random.

## Missing at random

Now suppose we remove smoking status values
so that more are missing from females than males.
```{r}
samples.mar <- samples[,c("smoking","sex","age")]
missing.idx <- sample(1:nrow(samples.mar),
                      floor(pct.missing*nrow(samples.mar)),
                      prob=ifelse(samples.mar$sex == "male", 0.2, 0.8))
samples.mar$smoking[missing.idx] <- NA
```

Have a look at the patterns.
```{r}
table(samples.mar$smoking, useNA="a")
md.pattern(samples.mar)
```

Investigate missingness by sex.
```{r}
table(sex=samples.mar$sex, missing=is.na(samples.mar$smoking))
```

We should see a correlation of missingness with sex.
```{r}
coef(summary(glm(is.na(smoking) ~ age + sex, data=samples.mar, family="binomial")))
```

## Ad hoc solutions for testing associations

### Solution: Complete case (CC) analysis

Here we just remove samples with missing values.

Here are the full data association statistics with CpG site cg07178945.
```{r}
data <- cbind(samples, sva.smoking)
data$cpg <- meth["cg07178945",]
coef(summary(lm(cpg ~ ., data)))["smokingnever",]
```

In the complete case analysis of MCAR, the association with smoking status
is still there but much weaker due to reduced sample size.
```{r}
data <- cbind(samples.mcar, sva.smoking)
data$cpg <- meth["cg07178945",]
data <- na.omit(data)
coef(summary(lm(cpg ~ ., data)))["smokingnever",]
```

The full data analysis of cg14024579.
```{r}
data <- cbind(samples, sva.smoking)
data$cpg <- meth["cg14024579",]
coef(summary(lm(cpg ~ ., data)))["smokingnever",]
```

This time, with complete case analysis of MAR, the association
becomes much stronger.
```{r}
data <- cbind(samples.mar, sva.smoking)
data$cpg <- meth["cg14024579",]
data <- na.omit(data)
coef(summary(lm(cpg ~ ., data)))["smokingnever",]
```

### Solution: Impute mean/median/mode

To avoid losing power, we could replace missing values
with 'reasonable' values, e.g. mean, median or mode.


The full data analysis of cg07178945.
```{r}
data <- cbind(samples, sva.smoking)
data$cpg <- meth["cg07178945",]
coef(summary(lm(cpg ~ ., data)))["smokingnever",]
```

Complete case:
```{r}
data <- cbind(samples.mis, sva.smoking)
data$cpg <- meth["cg07178945",]
coef(summary(lm(cpg ~ ., data)))["smokingnever",]
```

By imputing with the mode (most people are never smokers),
we reclassify many smokers as never smokers and reduce power.
```{r}
data <- cbind(samples.mcar, sva.smoking)
data$smoking[which(is.na(data$smoking))] <- names(which.max(table(samples.mcar$smoking)))
data$cpg <- meth["cg07178945",]
coef(summary(lm(cpg ~ ., data)))["smokingnever",]
```

In the missing-at-random dataset, imputation with the mode
weakens the association compared to complete case analysis.
```{r}
data <- cbind(samples.mar, sva.smoking)
data$smoking[which(is.na(data$smoking))] <- names(which.max(table(samples.mar$smoking)))
data$cpg <- meth["cg07178945",]
coef(summary(lm(cpg ~ ., data)))["smokingnever",]
```

### Solution: Imputing to conserve statistical properties

We can make the imputation a bit more interesting
by imputing randomly according to properties of the existing data.
In the smoking example, we impute randomly so that the ratio
of smokers to never-smokers remains the same.

Not an improvement in the association of cg21161138 with smoking in the MCAR
dataset compared to imputing the mode.

Mode:
```{r}
data <- cbind(samples.mcar, sva.smoking)
data$smoking[which(is.na(data$smoking))] <- names(which.max(table(samples.mcar$smoking)))
data$cpg <- meth["cg21161138",]
coef(summary(lm(cpg ~ ., data)))["smokingnever",]
```

```{r}
data <- cbind(samples.mcar, sva.smoking)
idx <- which(is.na(data$smoking))
p.smoker <- sum(data$smoking == "current", na.rm=T)/nrow(data)
data$smoking[idx] <- sample(c("current","never"),
                            size=length(idx),
                            prob=c(p.smoker, 1-p.smoker),
                            replace=T)
data$cpg <- meth["cg21161138",]
coef(summary(lm(cpg ~ ., data)))["smokingnever",]
```

### Solution: Multiple imputation

In multiple imputation, we attempt to allow other variables
to help decide on the best values to impute for each sample
instead of assigning values blindly.

Multiple imputation begins by imputing 'reasonable' values
for each variable (e.g. mean) and then repeatedly using
the currently imputed dataset to predict values for one of the
variables with missing values.
This is repeated some maximum number of iterations or until
values don't change much.

To take into account the uncertainty in the imputed values,
multiple datasets are imputed.  Downstream association
testing is then applied to each dataset and the summary
statistics pooled.

#### Simple example

To make things interesting, we remove values for both smoking and age.
```{r}
samples.mis <- samples
samples.mis$smoking[sample(1:nrow(samples.mis), 30)] <- NA
samples.mis$age[sample(1:nrow(samples.mis),30)] <- NA
```

For future reference, we identify the positions of missing values.
```{r}
smoking.idx <- which(is.na(samples.mis$smoking))
age.idx <- which(is.na(samples.mis$age))
```

We begin multiple imputation by filling in missing values with reasonable
starting values, e.g. mean or mode.
```{r}
samples.mis$smoking[smoking.idx] <- names(which.max(table(samples.mis$smoking)))
samples.mis$age[age.idx] <- mean(samples.mis$age, na.rm=T)
```

For comparison, we show the relationship of the imputed dataset with the
original dataset.
```{r}
table(samples.mis$smoking, samples$smoking)
cor(samples.mis$age, samples$age)
```

Next we predict age missing values using all other variables in the dataset.
```{r}
fit <- glm(age ~ ., samples.mis[-age.idx,], family="gaussian")
samples.mis$age[age.idx] <- predict(fit, newdata=samples.mis[age.idx,], type="response")
```

We do the same for smoking status.
```{r}
fit <- glm(sign(smoking == "current") ~ ., samples.mis[-smoking.idx,], family="binomial")
probs <- predict(fit, newdata=samples.mis[smoking.idx,], type="response")
samples.mis$smoking[smoking.idx] <- ifelse(probs > 0.5, "current", "never")
```

Unfortunately we observe no improvement.
```{r}
table(samples.mis$smoking, samples$smoking)
cor(samples.mis$age, samples$age)
```

This actually makes sense because none of the variables
in the dataset are strongly associated with age or smoking status.
```{r}
coef(summary(glm(smoking ~ ., samples, family=binomial)))
coef(summary(glm(age ~ ., samples, family=gaussian)))
```

#### Including DNA methylation to improve imputation

To improve imputation,
we include sites well-known to be predictive of smoking (cg05575921)
and age (cg21572722).
```{r}
samples.mis <- samples
samples.mis$cg05575921 <- meth["cg05575921",]
samples.mis$cg21572722 <- meth["cg21572722",]  
```

We also reset the dataset.
```{r}
samples.mis$age[age.idx] <- NA
samples.mis$smoking[smoking.idx] <- NA
samples.mis$smoking[smoking.idx] <- names(which.max(table(samples.mis$smoking)))
samples.mis$age[age.idx] <- mean(samples.mis$age, na.rm=T)
```

Once again, for reference we note comparison with the full dataset.
```{r}
table(samples.mis$smoking, samples$smoking)
cor(samples.mis$age, samples$age)
```

Again, we predict missing values using the other variables.
```{r}
fit <- glm(age ~ ., samples.mis[-age.idx,], family="gaussian")
samples.mis$age[age.idx] <- predict(fit, newdata=samples.mis[age.idx,], type="response")

fit <- glm(sign(smoking == "current") ~ ., samples.mis[-smoking.idx,], family="binomial")
probs <- predict(fit, newdata=samples.mis[smoking.idx,], type="response")
samples.mis$smoking[smoking.idx] <- ifelse(probs > 0.5, "current", "never")
```

We observe greater agreement with the full dataset.
```{r}
table(samples.mis$smoking, samples$smoking)
cor(samples.mis$age, samples$age)
```

We repeat prediction.
```{r}
fit <- glm(age ~ ., samples.mis[-age.idx,], family="gaussian")
samples.mis$age[age.idx] <- predict(fit, newdata=samples.mis[age.idx,], type="response")

fit <- glm(sign(smoking == "current") ~ ., samples.mis[-smoking.idx,], family="binomial")
probs <- predict(fit, newdata=samples.mis[smoking.idx,], type="response")
samples.mis$smoking[smoking.idx] <- ifelse(probs > 0.5, "current", "never")
```

This time we see no further improvement.
```{r}
table(samples.mis$smoking, samples$smoking)
cor(samples.mis$age, samples$age)
```

#### A more interesting example

To observe more interesting behaviour, we need
two variables that have missing values and
are associated with one another.

This time, we'll create missing values in the age variable
and the age-associated CpG site (cg21572722).
```{r}
set.seed(20180312)
samples.mis <- samples
samples.mis$cg21572722 <- meth["cg21572722",]
cg.idx <- sample(1:nrow(samples.mis), 20)
samples.mis$cg21572722[cg.idx] <- NA
samples.mis$age[age.idx] <- NA
samples.mis$cg21572722[cg.idx] <- mean(samples.mis$cg21572722, na.rm=T)
samples.mis$age[age.idx] <- mean(samples.mis$age, na.rm=T)
```

Ten times we'll predict values for each variable and compare to the full dataset.
```{r}
for (i in 1:8) {
    cat(i, cor(samples.mis$age, samples$age), cor(samples.mis$cg21572722, meth["cg21572722",]), "\n")
        
    fit <- glm(age ~ ., samples.mis[-age.idx,], family="gaussian")
    samples.mis$age[age.idx] <- predict(fit, newdata=samples.mis[age.idx,], type="response")

    fit <- glm(cg21572722 ~ ., samples.mis[-cg.idx,], family="gaussian")
    samples.mis$cg21572722[cg.idx] <- predict(fit, newdata=samples.mis[cg.idx,], type="response")
}
```

## Imputation using mice

Fortunately an R package is available to do most of this for us.

Once again, we create a dataset with missing age and CpG site values.
We include surrogate variables because we'll use `mice`
to illustrate the steps of an EWAS for a couple of CpG sites.
```{r}
set.seed(20180312)
samples.mis <- cbind(samples, sva=sva.age)
samples.mis$cg21572722 <- meth["cg21572722",]
cg.idx <- sample(1:nrow(samples.mis), 35)
samples.mis$cg21572722[cg.idx] <- NA
samples.mis$age[age.idx] <- NA
```

Imputation is completed with a single call to `mice()`.
Here ask to impute 10 datasets, each time predicting values
for each variable with missing values at most 10 times (`maxit`).
```{r}
library(mice)
imp <- mice(samples.mis, m=10, maxit=10, print=F, seed=20180312)
```

The prediction matrix determines which variables (columns) are used to
impute values for other variables (rows).
```{r}
imp$pred
```
A `1` indicates that the variable in the column is used to impute values for the
variable in the row.
Notice how there are 1's in the rows only of variables with missing values.

Within each imputed dataset, we can calculate the correlation of age with
the age variable in the full dataset.
```{r}
unlist(with(imp, cor(age, samples$age))$analyses)
quantile(unlist(with(imp, cor(age, samples$age))$analyses))
```

Here we fit a linear model in each imputed dataset.
```{r}
fit <- with(imp, lm(cg21572722 ~ age + smoking + sex + sva.1 + sva.2 + sva.3 + sva.4))
```

Therefore we have `r length(fit$analyses)` model fits. We show the summary statistics
for the first two.
```{r}
length(fit$analyses)
coef(summary(fit$analyses[[1]]))
coef(summary(fit$analyses[[2]]))
```

To obtain summary statistics across all model fits,
we 'pool' the summary statistics of each.
```{r}
pool.fit <- pool(fit)
```

The pooled summary statistics for 'age':
```{r}
summary(pool.fit)["age",]
```

The complete case association in this case is quite similar.
```{r}
fit.cc <- lm(cg21572722 ~ age + smoking + sex + sva.1 + sva.2 + sva.3 + sva.4, samples.mis)
coef(summary(fit.cc))["age",]
```

What if we consider another CpG site known to be associated with age but
was not included in the imputation?
```{r}
fit <- with(imp, lm(meth["cg27193080",] ~ age + smoking + sex + sva.1 + sva.2 + sva.3 + sva.4))
summary(pool(fit))["age",]
```

The complete case is much stronger ...
```{r}
fit.cc <- lm(meth["cg27193080",] ~ age + smoking + sex + sva.1 + sva.2 + sva.3 + sva.4, samples.mis)
coef(summary(fit.cc))["age",]
```

## Imputation for EWAS

### Option 1: Separate CpGs

1. Identify available variables known to be associated with each covariate with missing values.
2. For each CpG site:
2a. Impute N datasets including the CpG site methylation levels, all additional variables and covariates.
2b. Within each dataset fit a model to test association of the CpG site with variable of interest.
2c. Pool model fits to obtain association summary statistics (e.g. estimate, se, p-value).

In other words, for each CpG site `cg`:
```{r,eval=F}
data <- ... ## var, additional variables, covariates
for (cg in cgs) {
    data$cg <- meth[cg,]
    imp <- mice(data, ...)
    fit <- with(imp, lm(cg ~ var + score1 + score2 + ... + var1 + var2 + ... + cov1 + cov2 + ...))
    fit <- pool(fit)
    summary(fit)["var",] ## save summary statistics
}
```

Problem: Running time is very long.

### Option 2: Using associated CpGs – Naïve Method

1. To reduce running time, impute N datasets one time as above but
   excluding methylation levels of CpG sites (except for all those
   associated with the variable of interest).
2. For each CpG site, fit a model with each imputed dataset and pool model fits.

```{r,eval=F}
data <- ... ## var, additional variables, covariates, all CpG sites associated with var
imp <- mice(data, ...)
for (cg in cgs) {
    data$cg <- meth[cg,]
    fit <- with(imp, lm(cg ~ var + score1 + score2 + ... + var1 + var2 + ... + cov1 + cov2 + ...))
    fit <- pool(fit)
    summary(fit)["var",] ## save summary statistics    
}
```

Problem: Models can be very large and association testing
for CpG sites not included in the imputation are biased to the null.

### Option 3: Using associated CpGs – Wu Method

As above, but instead of just including all associated CpG sites,
construct a methylation predictor of the variable of interest
and include only those in the imputation model.

Wu et al. generated a predictor using forward-stepwise selection
from the set of 100 CpG most strongly associated with the
variable of interest in the complete-case dataset.

Problem: Also tends to bias CpG sites not included in the imputation
to null but not as badly as the Naive method.

### Option 4: Random bins of fixed size always including associated CpGs – Wu bins

Construct bins of CpG sites of size B such that:
1. Each CpG site in the Wu predictor appears in every bin, and
2. Each other CpG site appears in exactly one bin.

For each bin:
1. Impute N datasets with all CpG sites and all variables and covariates.
2. For each CpG site in the bin (except We predictor sites), fit a
   model for each dataset, pool the model fits and save summary
   statistics.

Bin size B is selected so that there is a 3:1 or 10:1 ratio of samples to
variables (i.e. variables, covariates, CpG sites) in the imputation models.

### Option 5: Random bins of fixed size

As above except that no predictors are generated
so each CpG site is randomly assigned to a single bin.

## R package for imputation in EWAS

Coming soon to the `ewaff` R package.  Here is what an imputation EWAS will be executed.
We'll use the random bins method.
```{r, eval=F}
imp <- ewaff.impute(methylation ~ age + smoking + sex, data, methylation, isv=TRUE)
```

Here we print out the Bonferroni-adjusted associations.
```{r, eval=F}
imp$table[which(imp$table$p.adjust < 0.05),]
```

